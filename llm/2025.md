

# 240127 Lookahead

论文：[[2312.12728\] Lookahead: An Inference Acceleration Framework for Large Language Model with Lossless Generation Accuracy](https://arxiv.org/abs/2312.12728)

中文解读：[【LLM推理】Lookahead：一种无损推理加速机制_lookahead llm-CSDN博客](https://blog.csdn.net/yjh_SE007/article/details/135879246)

现有优化推理方法如：量化（int8、GPTQ、KV Cache INT8等）、稀疏化、剪枝、知识蒸馏和张量分解等操作来减少LLMs的大小和降低推理速度。但这些技术往往会牺牲模型的准确性，既**有损优化**。

推理框架和推理引擎端，如： vLLM、TGI等推理框架，集成PagedAttention、FlashAttention等优化算法降低推理速度，是**无损优化**。

理论分析发现**IO带宽是主要瓶颈**：LLMs推理延迟的主要瓶颈是输入输出（IO）带宽，而不是与硬件计算能力相关的浮点运算（FLOPs）。这意味着，尽管LLMs在计算能力上可能很强大，但由于IO限制，它们的推理速度仍然受到限制。

本文介绍了Lookahead框架，这是一个通用的推理加速框架，主要针对RAG场景，旨在通过多分支策略和Trie树结构来提高推理速度，同时保持生成结果的准确性。

---

总结：

lookahead是一种投机采样方法。

通过Mask策略实现一次验证多个token序列或token前缀树。



# 250203 test-time compute

原文：[A Visual Guide to Reasoning LLMs - by Maarten Grootendorst](https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-reasoning-llms)

中文解读：[可视化角度具象化理解DeepSeek-R1类推理大模型的习得进程](https://mp.weixin.qq.com/s/ytKTGTgU2T7jSNrBghX1cA)

在整个 2024 年，计算、数据集大小和模型参数稳步增长，但收益却显示出递减的回报。

OpenAI 在9月 [的一篇文章](https://openai.com/index/learning-to-reason-with-llms/) 表明，test-time compute实际上可能遵循与train-time compute相同的scaling law。

测试时计算可以做很多事情，包括 Chain-of-Thought、修改答案(revising answers)、回溯(backtracking)、采样(sampling)等等。

上文作者将test-time compute方法分为两类：

- Search against Verifiers (sampling generations and selecting the best answer)
  针对验证者进行搜索（进行采样并选择最佳答案）
- Modifying Proposal Distribution (trained “thinking” process)
  修改提议分布（经过训练的“思考”过程）

---

加上个人阅读后的一些理解，重新将 test-time compute方法分为两类：

- 训练resoning模型：推理时是LLM自发行为。
- 修改提议分布：通过提示词、采样方法改变LLM推理行为。

当前推理模型：DeepSeek-R1-Zero，Simple Scaling S1等

修改提议分布之提示词技术：CoT、Least to Most、ToT、ReAct、Reflexion等

修改提议分布之采样方法：多数投票、Best-of-N, Beam Search, MCTS等

# 25010207 s1

原文：[simplescaling/s1: s1: Simple test-time scaling](https://github.com/simplescaling/s1)

中文解读：[算力人再次天塌？李飞飞的s1是怎么炼成的_李飞飞 s1-CSDN博客](https://blog.csdn.net/kingsoftcloud/article/details/145480274)

研究过程中，团队提出了一种简单的解码时间干预方法**budget forcing，在测试时强制设定最大和/或最小的思考token数量。**

具体来说，研究者使用了一种很简单的办法：

直接添加“end-of-thinking token分隔符”和“Final Answer”，来**强制设定思考token数量上限**，从而让模型提前结束思考阶段，并促使它提供当前思考过程中的最佳答案。

---

1000条长推理数据：

- 问题来自各个开源数据集（选择较难的问题）
- 答案由Google Gemini Flash Thinking API生成
- 数学偏多

Test-time intervention：主要通过 **“预算强制 (Budget forcing)”** 和 **“拒绝采样 (Rejection sampling)”** 两种方法来实现。



